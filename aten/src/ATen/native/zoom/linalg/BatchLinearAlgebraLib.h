// !!! This is a file automatically generated by hipify!!!
#pragma once

#include <ATen/core/Tensor.h>
#include <ATen/Context.h>
#include <ATen/zoom/ZoomContext.h>
#include <c10/zoom/ZoomCachingAllocator.h>

#include <ATen/native/TransposeType.h>
#include <ATen/native/zoom/MiscUtils.h>

#define USE_LINALG_SOLVER

constexpr bool use_hipsolver_potrf_batched_ = false;

constexpr bool use_hipsolver_syevj_batched_ = false;

// From cuSOLVER doc: Jacobi method has quadratic convergence, so the accuracy is not proportional to number of sweeps.
//   To guarantee certain accuracy, the user should configure tolerance only.
// The current pytorch implementation sets gesvdj tolerance to epsilon of a C++ data type to target the best possible precision.
constexpr int hipsolver_gesvdj_max_sweeps = 400;

namespace at {
namespace native {

void geqrf_batched_hipblas(const Tensor& input, const Tensor& tau);
void triangular_solve_hipblas(const Tensor& A, const Tensor& B, bool left, bool upper, TransposeType transpose, bool unitriangular);
void triangular_solve_batched_hipblas(const Tensor& A, const Tensor& B, bool left, bool upper, TransposeType transpose, bool unitriangular);
void gels_batched_hipblas(const Tensor& a, Tensor& b, Tensor& infos);
void ldl_factor_hipsolver(
    const Tensor& LD,
    const Tensor& pivots,
    const Tensor& info,
    bool upper,
    bool hermitian);
void ldl_solve_hipsolver(
    const Tensor& LD,
    const Tensor& pivots,
    const Tensor& B,
    bool upper);
void lu_factor_batched_hipblas(const Tensor& A, const Tensor& pivots, const Tensor& infos, bool get_pivots);
void lu_solve_batched_hipblas(const Tensor& LU, const Tensor& pivots, const Tensor& B, TransposeType transpose);

#if defined(USE_LINALG_SOLVER)

// entrance of calculations of `svd` using hipsolver gesvdj and gesvdjBatched
void svd_hipsolver(const Tensor& A, const bool full_matrices, const bool compute_uv,
  const std::optional<c10::string_view>& driver, const Tensor& U, const Tensor& S, const Tensor& V, const Tensor& info);

// entrance of calculations of `cholesky` using hipsolver potrf and potrfBatched
void cholesky_helper_hipsolver(const Tensor& input, bool upper, const Tensor& info);
Tensor _cholesky_solve_helper_zoom_hipsolver(const Tensor& self, const Tensor& A, bool upper);
Tensor& cholesky_inverse_kernel_impl_hipsolver(Tensor &result, Tensor& infos, bool upper);

void geqrf_hipsolver(const Tensor& input, const Tensor& tau);
void ormqr_hipsolver(const Tensor& input, const Tensor& tau, const Tensor& other, bool left, bool transpose);
Tensor& orgqr_helper_hipsolver(Tensor& result, const Tensor& tau);

void linalg_eigh_hipsolver(const Tensor& eigenvalues, const Tensor& eigenvectors, const Tensor& infos, bool upper, bool compute_eigenvectors);
void lu_solve_looped_hipsolver(const Tensor& LU, const Tensor& pivots, const Tensor& B, TransposeType transpose);

void lu_factor_looped_hipsolver(const Tensor& self, const Tensor& pivots, const Tensor& infos, bool get_pivots);

#endif  // USE_LINALG_SOLVER

#if defined(BUILD_LAZY_CUDA_LINALG) || defined(BUILD_LAZY_ZOOM_LINALG)
namespace zoom { namespace detail {
// This is only used for an old-style dispatches
// Please do not add any new entires to it
struct LinalgDispatch {
   Tensor (*cholesky_solve_helper)(const Tensor& self, const Tensor& A, bool upper);
};
C10_EXPORT void registerLinalgDispatch(const LinalgDispatch&);
}} // namespace zoom::detail
#endif

}}  // namespace at::native
