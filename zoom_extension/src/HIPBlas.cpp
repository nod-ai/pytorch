// !!! This is a file automatically generated by hipify!!!
/*
  Provides the implementations of CUDA BLAS function templates.
 */

#include <ATen/ATen.h>
#include "HIPBlas.h"
#include "ZoomException.h"
#include "ZoomDataType.h"
#include "./tunable/Tunable.h"
#include "./tunable/TunableGemm.h"
#include "ZoomCachingAllocator.h"
#include "ZoomFunctions.h"
#include <c10/macros/Export.h>
#include <c10/util/irange.h>

#ifndef DISABLE_HIPBLASLT
#include <hipblaslt/hipblaslt-ext.hpp>
#endif
// until hipblas has an API to accept flags, we must use rocblas here
#include <hipblas/hipblas.h>
#include <rocblas/rocblas.h>
#define PYTORCH_ROCBLAS_VERSION_DECIMAL (ROCBLAS_VERSION_MAJOR * 100 + ROCBLAS_VERSION_MINOR)
#define USE_GEMM_FLAGS_FP16_ALT_IMPL (PYTORCH_ROCBLAS_VERSION_DECIMAL >= 242)
// needed to work around calling rocblas API instead of hipblas API
static rocblas_operation hipOperationToRocOperation(hipblasOperation_t op)
{
    switch(op)
    {
    case HIPBLAS_OP_N:
        return rocblas_operation_none;
    case HIPBLAS_OP_T:
        return rocblas_operation_transpose;
    case HIPBLAS_OP_C:
        return rocblas_operation_conjugate_transpose;
    }
    AT_ERROR("HIPBLAS_STATUS_INVALID_ENUM");
}
static hipblasStatus_t rocBLASStatusToHIPStatus(rocblas_status error)
{
    switch(error)
    {
    case rocblas_status_size_unchanged:
    case rocblas_status_size_increased:
    case rocblas_status_success:
        return HIPBLAS_STATUS_SUCCESS;
    case rocblas_status_invalid_handle:
        return HIPBLAS_STATUS_NOT_INITIALIZED;
    case rocblas_status_not_implemented:
        return HIPBLAS_STATUS_NOT_SUPPORTED;
    case rocblas_status_invalid_pointer:
    case rocblas_status_invalid_size:
    case rocblas_status_invalid_value:
        return HIPBLAS_STATUS_INVALID_VALUE;
    case rocblas_status_memory_error:
        return HIPBLAS_STATUS_ALLOC_FAILED;
    case rocblas_status_internal_error:
        return HIPBLAS_STATUS_INTERNAL_ERROR;
    }
    AT_ERROR("HIPBLAS_STATUS_INVALID_ENUM");
}

// (Arham): torch cpp_extension auto defines HIPBLAS_V2 without checking versions which causes issues, hence we redefine here
#if (defined(hipblasVersionMajor) && hipblasVersionMajor == 2)
  #ifndef HIPBLAS_V2
    #define HIPBLAS_V2
  #endif
#else
  #ifdef HIPBLAS_V2
    #undef HIPBLAS_V2
  #endif
#endif

// hipblas does not have hipblasSetMathMode
#define hipblasSetMathMode(handle, flags) HIPBLAS_STATUS_SUCCESS
// until we use hiblas v2
// hipify correctly maps things like HIP_R_16F to HIP_R_16F,
// however hipblas v1 is still using its custom type
#ifndef HIPBLAS_V2
  #define HIP_R_16F  HIPBLAS_R_16F
  #define HIP_R_32F  HIPBLAS_R_32F
  #define HIP_R_64F  HIPBLAS_R_64F
  #define HIP_C_16F  HIPBLAS_C_16F
  #define HIP_C_32F  HIPBLAS_C_32F
  #define HIP_C_64F  HIPBLAS_C_64F
  #define HIP_R_8I   HIPBLAS_R_8I
  #define HIP_R_8U   HIPBLAS_R_8U
  #define HIP_R_32I  HIPBLAS_R_32I
  #define HIP_R_32U  HIPBLAS_R_32U
  #define HIP_C_8I   HIPBLAS_C_8I
  #define HIP_C_8U   HIPBLAS_C_8U
  #define HIP_C_32I  HIPBLAS_C_32I
  #define HIP_C_32U  HIPBLAS_C_32U
  #define HIP_R_16BF HIPBLAS_R_16B
  #define HIP_C_16BF HIPBLAS_C_16B

  // hipblas v2 uses classic HIP types to represent complex data types but hipblas v1 needs its custom types
  #define hipComplex hipblasComplex
  #define hipDoubleComplex hipblasDoubleComplex
#endif


#define CUDABLAS_POSINT_CHECK(FD, X)         \
  TORCH_CHECK(                               \
      (X > 0 && X <= INT_MAX),               \
      "at::zoom::blas::" #FD " argument " #X \
      " must be positive and less than ",    \
      INT_MAX,                               \
      " but got ",                           \
      X)

#define CUDABLAS_NONNEGINT_CHECK(FD, X)       \
  TORCH_CHECK(                                \
      (X >= 0 && X <= INT_MAX),               \
      "at::zoom::blas::" #FD " argument " #X  \
      " must be non-negative and less than ", \
      INT_MAX,                                \
      " but got ",                            \
      X)

namespace {

static hipblasOperation_t _hipblasOpFromChar(char op) {
  switch (op) {
    case 'n':
    case 'N':
      return HIPBLAS_OP_N;
    case 't':
    case 'T':
      return HIPBLAS_OP_T;
    case 'c':
    case 'C':
      return HIPBLAS_OP_C;
  }
  AT_ERROR(
      "_hipblasOpFromChar input should be 't', 'n' or 'c' but got `", op, "`");
}

static void _hipblasAdjustLdLevel2(int64_t m, int64_t n, int64_t* lda) {
  // Note: leading dimensions generally are checked that they are > 0
  // and at least as big the result requires (even if the value won't
  // be used).

  // Q: Why does Level3 check trans but this doesn't?
  // A: In level 2, the sizes (m, n) specify the size of A
  // (independent of trans value). In level 3. the sizes (m, n, k)
  // specify the sizes of op(A), op(B) where op depend on trans
  // values.
  if (n <= 1)
    *lda = std::max<int64_t>(m, 1);
}

static void _hipblasAdjustLdLevel3(
    char transa,
    char transb,
    int64_t m,
    int64_t n,
    int64_t k,
    int64_t* lda,
    int64_t* ldb,
    int64_t* ldc) {
  bool transa_ = ((transa != 'n') && (transa != 'N'));
  bool transb_ = ((transb != 'n') && (transb != 'N'));

  // Note: leading dimensions generally are checked that they are > 0
  // and at least as big the result requires (even if the value won't
  // be used).
  if (n <= 1)
    *ldc = std::max<int64_t>(m, 1);

  if (transa_) {
    if (m <= 1)
      *lda = std::max<int64_t>(k, 1);
  } else {
    if (k <= 1)
      *lda = std::max<int64_t>(m, 1);
  }

  if (transb_) {
    if (k <= 1)
      *ldb = std::max<int64_t>(n, 1);
  } else {
    if (n <= 1)
      *ldb = std::max<int64_t>(k, 1);
  }
}


static size_t _parseChosenWorkspaceSize() {
  const char * val = getenv("CUBLASLT_WORKSPACE_SIZE");
  if (!val) {
    // accept either env var
    val = getenv("HIPBLASLT_WORKSPACE_SIZE");
  }
  size_t workspace_size = 1024; /* default size in KiB according to #73328 */
  if (val) {
    try {
      workspace_size = std::stoi(val);
    } catch(std::invalid_argument const& e) {
      TORCH_WARN("invalid HIPBLASLT_WORKSPACE_SIZE,",
                 " using default workspace size of ", workspace_size, " KiB.");
    } catch(std::out_of_range const& e) {
      TORCH_WARN("HIPBLASLT_WORKSPACE_SIZE out of range,",
                 " using default workspace size of ", workspace_size, " KiB.");
    }
  }
  return workspace_size * 1024;
}

static size_t _getWorkspaceSize() {
  static size_t workspace_size = _parseChosenWorkspaceSize();
  return workspace_size;
}

} // anonymous namespace

namespace at::zoom::blas {

/* LEVEL 3 BLAS FUNCTIONS */

#define GEMM_CHECK_ARGVALUES(Dtype)           \
  do {                                        \
    CUDABLAS_NONNEGINT_CHECK(gemm<Dtype>, m); \
    CUDABLAS_NONNEGINT_CHECK(gemm<Dtype>, n); \
    CUDABLAS_NONNEGINT_CHECK(gemm<Dtype>, k); \
    CUDABLAS_POSINT_CHECK(gemm<Dtype>, lda);  \
    CUDABLAS_POSINT_CHECK(gemm<Dtype>, ldb);  \
    CUDABLAS_POSINT_CHECK(gemm<Dtype>, ldc);  \
  } while (0)

#define BGEMM_CHECK_ARGVALUES(Dtype)           \
  do {                                        \
    CUDABLAS_NONNEGINT_CHECK(bgemm<Dtype>, m); \
    CUDABLAS_NONNEGINT_CHECK(bgemm<Dtype>, n); \
    CUDABLAS_NONNEGINT_CHECK(bgemm<Dtype>, k); \
    CUDABLAS_POSINT_CHECK(bgemm<Dtype>, lda);  \
    CUDABLAS_POSINT_CHECK(bgemm<Dtype>, ldb);  \
    CUDABLAS_POSINT_CHECK(bgemm<Dtype>, ldc);  \
    CUDABLAS_NONNEGINT_CHECK(bgemm<Dtype>, num_batches);  \
  } while (0)


#ifndef DISABLE_HIPBLASLT
namespace {
// Following the pattern of CuSparseDescriptor
// Defined here for now because this is the only place hipblas_lt interface is
// used but can be moved to a header once hipblas_lt interface is used in
// multiple places.
template <typename T, hipblasStatus_t (*destructor)(T*)>
struct CuBlasLtDeleter {
  void operator()(T* x) {
    if (x != nullptr) {
      TORCH_HIPBLAS_CHECK(destructor(x));
    }
  }
};

template <typename T, hipblasStatus_t (*destructor)(T*)>
class CuBlasLtDescriptor {
 public:
  T* descriptor() const {
    return descriptor_.get();
  }
  T* descriptor() {
    return descriptor_.get();
  }

 protected:
  std::unique_ptr<T, CuBlasLtDeleter<T, destructor>> descriptor_;
};

class CuBlasLtMatmulDescriptor : public CuBlasLtDescriptor<
                                     hipblasLtMatmulDescOpaque_t,
                                     &hipblasLtMatmulDescDestroy> {
 public:
  CuBlasLtMatmulDescriptor(
      hipblasComputeType_t compute_type,
      hipDataType scale_type) {
    hipblasLtMatmulDesc_t raw_descriptor = nullptr;
    TORCH_HIPBLAS_CHECK(
        hipblasLtMatmulDescCreate(&raw_descriptor, compute_type, scale_type));
    descriptor_.reset(raw_descriptor);
  }
  template <typename T>
  inline void setAttribute(hipblasLtMatmulDescAttributes_t attr, const T value) {
    TORCH_HIPBLAS_CHECK(::hipblasLtMatmulDescSetAttribute(descriptor(), attr, &value, sizeof(T)));
  }
};

class CuBlasLtMatrixLayout : public CuBlasLtDescriptor<
                                 hipblasLtMatrixLayoutOpaque_t,
                                 &hipblasLtMatrixLayoutDestroy> {
 public:
  CuBlasLtMatrixLayout(
      hipDataType type,
      uint64_t rows,
      uint64_t cols,
      int64_t ld,
      bool t = false) {
    hipblasLtMatrixLayout_t raw_descriptor = nullptr;
    TORCH_HIPBLAS_CHECK(
        hipblasLtMatrixLayoutCreate(&raw_descriptor, type, t ? cols : rows, t ? rows : cols, ld));
    descriptor_.reset(raw_descriptor);
  }
  template <typename T>
  inline void setAttribute(hipblasLtMatrixLayoutAttribute_t attr, const T value) {
    TORCH_HIPBLAS_CHECK(::hipblasLtMatrixLayoutSetAttribute(descriptor(), attr, &value, sizeof(T)));
  }
};

class CuBlasLtMatmulPreference : public CuBlasLtDescriptor<
                                     hipblasLtMatmulPreferenceOpaque_t,
                                     &hipblasLtMatmulPreferenceDestroy> {
 public:
  CuBlasLtMatmulPreference() {
    hipblasLtMatmulPreference_t raw_descriptor = nullptr;
    TORCH_HIPBLAS_CHECK(hipblasLtMatmulPreferenceCreate(&raw_descriptor));
    descriptor_.reset(raw_descriptor);
  }
  template <typename T>
  inline void setAttribute(hipblasLtMatmulPreferenceAttributes_t attr, const T value) {
    TORCH_HIPBLAS_CHECK(::hipblasLtMatmulPreferenceSetAttribute(descriptor(), attr, &value, sizeof(T)));
  }
};
} // namespace
#endif


template <typename Dtype>
inline void bgemm_internal_hipblaslt(CUDABLAS_BGEMM_ARGTYPES(Dtype)) {
  #ifdef DISABLE_HIPBLASLT
  TORCH_CHECK_DISABLE_HIPBLAS_LT
  #else
  hipDataType abcType = HIP_R_32F;
  hipblasComputeType_t computeType = HIPBLAS_COMPUTE_32F;
  hipDataType scaleType = HIP_R_32F;
  if constexpr (std::is_same_v<Dtype, double>) {
    abcType = HIP_R_64F;
    computeType = HIPBLAS_COMPUTE_64F;
    scaleType = HIP_R_64F;
  } else if constexpr (std::is_same_v<Dtype, float>) {

  } else if constexpr (std::is_same_v<Dtype, c10::complex<double>>) {
    abcType = HIP_C_64F;
    computeType = HIPBLAS_COMPUTE_64F;
    scaleType = HIP_C_64F;
  } else if constexpr (std::is_same_v<Dtype, c10::complex<float>>) {
    abcType = HIP_C_32F;
    scaleType = HIP_C_32F;
  } else if constexpr (std::is_same_v<Dtype, at::Half>) {
    abcType = HIP_R_16F;
  } else if constexpr (std::is_same_v<Dtype, at::BFloat16>) {
    abcType = HIP_R_16BF;
  } else {
    AT_ERROR("at::zoom::blas::bgemm_internal_hipblaslt: not implemented for ", typeid(Dtype).name());
  }

  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasLtHandle_t ltHandle = at::zoom::getCurrentHIPBlasLtHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);

  CuBlasLtMatmulDescriptor computeDesc(computeType, scaleType);
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSA, opa);
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSB, opb);
  CuBlasLtMatrixLayout Adesc(abcType, m, k, lda, opa == HIPBLAS_OP_T);
  CuBlasLtMatrixLayout Bdesc(abcType, k, n, ldb, opb == HIPBLAS_OP_T);
  CuBlasLtMatrixLayout Cdesc(abcType, m, n, ldc);

  if (num_batches > 1) {
    int num_batches_as_int = static_cast<int>(num_batches);
    Adesc.setAttribute(HIPBLASLT_MATRIX_LAYOUT_BATCH_COUNT, num_batches_as_int);
    Bdesc.setAttribute(HIPBLASLT_MATRIX_LAYOUT_BATCH_COUNT, num_batches_as_int);
    Cdesc.setAttribute(HIPBLASLT_MATRIX_LAYOUT_BATCH_COUNT, num_batches_as_int);
    Adesc.setAttribute(HIPBLASLT_MATRIX_LAYOUT_STRIDED_BATCH_OFFSET, stridea);
    Bdesc.setAttribute(HIPBLASLT_MATRIX_LAYOUT_STRIDED_BATCH_OFFSET, strideb);
    Cdesc.setAttribute(HIPBLASLT_MATRIX_LAYOUT_STRIDED_BATCH_OFFSET, stridec);
  }

  CuBlasLtMatmulPreference preference;
  // See https://github.com/pytorch/pytorch/issues/73328 for reasoning behind
  // setting this to 1M.
  size_t workspaceSize = _getWorkspaceSize();
  preference.setAttribute(HIPBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES, workspaceSize);

  auto& allocator = *::c10::zoom::ZoomCachingAllocator::get();
  auto workspace = allocator.allocate(workspaceSize);
  TORCH_CHECK(workspace.get() != nullptr, "OOM trying to allocate workspace for hipblaslt");

  hipblasLtMatmulHeuristicResult_t heuristicResult = {};
  int returnedResult = 0;
  TORCH_HIPBLAS_CHECK(hipblasLtMatmulAlgoGetHeuristic(
      ltHandle,
      computeDesc.descriptor(),
      Adesc.descriptor(),
      Bdesc.descriptor(),
      Cdesc.descriptor(),
      Cdesc.descriptor(),
      preference.descriptor(),
      1,
      &heuristicResult,
      &returnedResult));
  if (returnedResult == 0) {
    TORCH_HIPBLAS_CHECK(HIPBLAS_STATUS_NOT_SUPPORTED);
  }

  hipblasStatus_t hipblasStatus = hipblasLtMatmul(
      ltHandle,
      computeDesc.descriptor(),
      &alpha,
      a,
      Adesc.descriptor(),
      b,
      Bdesc.descriptor(),
      &beta,
      c,
      Cdesc.descriptor(),
      c,
      Cdesc.descriptor(),
      &heuristicResult.algo,
      workspace.mutable_get(),
      workspaceSize,
      c10::zoom::GetCurrentZoomStream());
  TORCH_CHECK(
      hipblasStatus == HIPBLAS_STATUS_SUCCESS,
      "CUDA error: ",
      at::zoom::blas::_hipblasGetErrorEnum(hipblasStatus),
      " when calling hipblasLtMatmul with transpose_mat1 ",
      (opa == HIPBLAS_OP_T),
      " transpose_mat2 ",
      (opb == HIPBLAS_OP_T),
      " m ",
      m,
      " n ",
      n,
      " k ",
      k,
      " lda ",
      lda,
      " ldb ",
      ldb,
      " ldc ",
      ldc,
      " abcType ",
      abcType,
      " computeType ",
      computeType,
      " scaleType ",
      scaleType);
  #endif
}


template <typename Dtype>
inline void bgemm_internal_hipblas(CUDABLAS_BGEMM_ARGTYPES(Dtype)) {
  AT_ERROR("at::zoom::blas::bgemm_internal_hipblas: not implemented for ", typeid(Dtype).name());
}

template <>
void bgemm_internal_hipblas<double>(CUDABLAS_BGEMM_ARGTYPES(double)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  BGEMM_CHECK_ARGVALUES(double);
  TORCH_HIPBLAS_CHECK(hipblasDgemmStridedBatched(
      handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches));
}

template <>
void bgemm_internal_hipblas<float>(CUDABLAS_BGEMM_ARGTYPES(float)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  BGEMM_CHECK_ARGVALUES(float);
  TORCH_HIPBLAS_CHECK(hipblasSgemmStridedBatched(
      handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches));
}

template <>
void bgemm_internal_hipblas<c10::complex<double>>(CUDABLAS_BGEMM_ARGTYPES(c10::complex<double>)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  BGEMM_CHECK_ARGVALUES(c10::complex<double>);
  TORCH_HIPBLAS_CHECK(hipblasZgemmStridedBatched(
      handle, opa, opb, m, n, k, reinterpret_cast<const hipDoubleComplex*>(&alpha), reinterpret_cast<const hipDoubleComplex*>(a),
      lda, stridea, reinterpret_cast<const hipDoubleComplex*>(b), ldb, strideb, reinterpret_cast<const hipDoubleComplex*>(&beta),
      reinterpret_cast<hipDoubleComplex*>(c), ldc, stridec, num_batches));
}

template <>
void bgemm_internal_hipblas<c10::complex<float>>(CUDABLAS_BGEMM_ARGTYPES(c10::complex<float>)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  BGEMM_CHECK_ARGVALUES(c10::complex<float>);
  TORCH_HIPBLAS_CHECK(hipblasCgemmStridedBatched(
      handle, opa, opb, m, n, k, reinterpret_cast<const hipComplex*>(&alpha), reinterpret_cast<const hipComplex*>(a),
      lda, stridea, reinterpret_cast<const hipComplex*>(b), ldb, strideb, reinterpret_cast<const hipComplex*>(&beta),
      reinterpret_cast<hipComplex*>(c), ldc, stridec, num_batches));
}

template <>
void bgemm_internal_hipblas<at::Half>(CUDABLAS_BGEMM_ARGTYPES(at::Half)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  BGEMM_CHECK_ARGVALUES(at::Half);
  float falpha = alpha;
  float fbeta = beta;

  int flag = 0;
#if USE_GEMM_FLAGS_FP16_ALT_IMPL
  flag = at::ROCmBackwardPassGuard::is_backward_pass() ? rocblas_gemm_flags_fp16_alt_impl : 0;
#endif
  TORCH_HIPBLAS_CHECK(rocBLASStatusToHIPStatus(rocblas_gemm_strided_batched_ex((rocblas_handle)handle,
                                   hipOperationToRocOperation(opa),
                                   hipOperationToRocOperation(opb), (int)m, (int)n, (int)k,
                                   (void*)&falpha, a, rocblas_datatype_f16_r, (int)lda, stridea,
                                   b, rocblas_datatype_f16_r, (int)ldb, strideb,
                                   (void*)&fbeta, c, rocblas_datatype_f16_r, (int)ldc, stridec,
                                   c, rocblas_datatype_f16_r, (int)ldc, stridec,
                                   (int) num_batches, rocblas_datatype_f32_r, rocblas_gemm_algo_standard,
                                   0, flag)));
}

template <>
void bgemm_internal_hipblas<at::BFloat16>(CUDABLAS_BGEMM_ARGTYPES(at::BFloat16)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  BGEMM_CHECK_ARGVALUES(at::BFloat16);
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  const float falpha = alpha;
  const float fbeta = beta;
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);

  #ifdef HIPBLAS_V2
  auto compute_type = HIPBLAS_COMPUTE_32F;
  #else
  auto compute_type = HIP_R_16BF;
  #endif

  TORCH_HIPBLAS_CHECK(hipblasGemmStridedBatchedEx(handle,
                                  opa, opb, (int)m, (int)n, (int)k,
                                  (void*)&falpha, a, HIP_R_16BF, (int)lda, stridea,
                                  b, HIP_R_16BF, (int)ldb, strideb,
                                  (void*)&fbeta, c, HIP_R_16BF, (int)ldc, stridec,
                                  (int)num_batches,
                                  compute_type,
                                  HIPBLAS_GEMM_DEFAULT));
}

template <>
void bgemm_internal<double>(CUDABLAS_BGEMM_ARGTYPES(double))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    // hipblaslt does not support double gemm yet
    bgemm_internal_hipblas<double>(CUDABLAS_BGEMM_ARGS(double));
  }
  else {
    bgemm_internal_hipblas<double>(CUDABLAS_BGEMM_ARGS(double));
  }
}

template <>
void bgemm_internal<float>(CUDABLAS_BGEMM_ARGTYPES(float))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    #ifdef DISABLE_HIPBLASLT
    TORCH_WARN_DISABLE_HIPBLASLT
    bgemm_internal_hipblas<float>(CUDABLAS_BGEMM_ARGS(float));
    #else
    bgemm_internal_hipblaslt<float>(CUDABLAS_BGEMM_ARGS(float));
    #endif
  }
  else {
    bgemm_internal_hipblas<float>(CUDABLAS_BGEMM_ARGS(float));
  }
}

template <>
void bgemm_internal<c10::complex<double>>(CUDABLAS_BGEMM_ARGTYPES(c10::complex<double>))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    // hipblaslt does not support complex<double> gemm yet
    bgemm_internal_hipblas<c10::complex<double>>(CUDABLAS_BGEMM_ARGS(c10::complex<double>));
  }
  else {
    bgemm_internal_hipblas<c10::complex<double>>(CUDABLAS_BGEMM_ARGS(c10::complex<double>));
  }
}

template <>
void bgemm_internal<c10::complex<float>>(CUDABLAS_BGEMM_ARGTYPES(c10::complex<float>))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    // hipblaslt does not support complex<float> gemm yet
    bgemm_internal_hipblas<c10::complex<float>>(CUDABLAS_BGEMM_ARGS(c10::complex<float>));
  }
  else {
    bgemm_internal_hipblas<c10::complex<float>>(CUDABLAS_BGEMM_ARGS(c10::complex<float>));
  }
}

template <>
void bgemm_internal<at::Half>(CUDABLAS_BGEMM_ARGTYPES(at::Half))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    #ifdef DISABLE_HIPBLASLT
    TORCH_WARN_DISABLE_HIPBLASLT
    bgemm_internal_hipblas<at::Half>(CUDABLAS_BGEMM_ARGS(at::Half));
    #else
    bgemm_internal_hipblaslt<at::Half>(CUDABLAS_BGEMM_ARGS(at::Half));
    #endif
  }
  else {
    bgemm_internal_hipblas<at::Half>(CUDABLAS_BGEMM_ARGS(at::Half));
  }
}

template <>
void bgemm_internal<at::BFloat16>(CUDABLAS_BGEMM_ARGTYPES(at::BFloat16))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    #ifdef DISABLE_HIPBLASLT
    TORCH_WARN_DISABLE_HIPBLASLT
    bgemm_internal_hipblas<at::BFloat16>(CUDABLAS_BGEMM_ARGS(at::BFloat16));
    #else
    bgemm_internal_hipblaslt<at::BFloat16>(CUDABLAS_BGEMM_ARGS(at::BFloat16));
    #endif
  }
  else {
    bgemm_internal_hipblas<at::BFloat16>(CUDABLAS_BGEMM_ARGS(at::BFloat16));
  }
}

template <typename DType>
inline void bgemm_tunable(CUDABLAS_BGEMM_ARGTYPES(DType)) {
  tunable::GemmStridedBatchedParams<DType> params;
  params.transa = transa;
  params.transb = transb;
  params.m = m;
  params.n = n;
  params.k = k;
  params.alpha = alpha;
  params.a = a;
  params.lda = lda;
  params.stride_a = stridea;
  params.b = b;
  params.ldb = ldb;
  params.stride_b = strideb;
  params.beta = beta;
  params.c = c;
  params.ldc = ldc;
  params.stride_c = stridec;
  params.batch = num_batches;

  bool transa_ = ((transa != 'n') && (transa != 'N'));
  bool transb_ = ((transb != 'n') && (transb != 'N'));

  if (transa_ && transb_) {
    static tunable::GemmStridedBatchedTunableOp<DType, tunable::BlasOp::T, tunable::BlasOp::T> bgemm{};
    bgemm(&params);
  }
  else if (transa_ && !transb_) {
    static tunable::GemmStridedBatchedTunableOp<DType, tunable::BlasOp::T, tunable::BlasOp::N> bgemm{};
    bgemm(&params);
  }
  else if (!transa_ && transb_) {
    static tunable::GemmStridedBatchedTunableOp<DType, tunable::BlasOp::N, tunable::BlasOp::T> bgemm{};
    bgemm(&params);
  }
  else if (!transa_ && !transb_) {
    static tunable::GemmStridedBatchedTunableOp<DType, tunable::BlasOp::N, tunable::BlasOp::N> bgemm{};
    bgemm(&params);
  }
  else {
    TORCH_CHECK(false, "unreachable");
  }
}

template <>
void bgemm<double>(CUDABLAS_BGEMM_ARGTYPES(double)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    bgemm_tunable<double>(CUDABLAS_BGEMM_ARGS(double));
  }
  else {
    bgemm_internal<double>(CUDABLAS_BGEMM_ARGS(double));
  }
}

template <>
void bgemm<float>(CUDABLAS_BGEMM_ARGTYPES(float)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    bgemm_tunable<float>(CUDABLAS_BGEMM_ARGS(float));
  }
  else {
    bgemm_internal<float>(CUDABLAS_BGEMM_ARGS(float));
  }
}

template <>
void bgemm<c10::complex<double>>(CUDABLAS_BGEMM_ARGTYPES(c10::complex<double>)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    bgemm_tunable<c10::complex<double>>(CUDABLAS_BGEMM_ARGS(c10::complex<double>));
  }
  else {
    bgemm_internal<c10::complex<double>>(CUDABLAS_BGEMM_ARGS(c10::complex<double>));
  }
}

template <>
void bgemm<c10::complex<float>>(CUDABLAS_BGEMM_ARGTYPES(c10::complex<float>)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    bgemm_tunable<c10::complex<float>>(CUDABLAS_BGEMM_ARGS(c10::complex<float>));
  }
  else {
    bgemm_internal<c10::complex<float>>(CUDABLAS_BGEMM_ARGS(c10::complex<float>));
  }
}

template <>
void bgemm<at::Half>(CUDABLAS_BGEMM_ARGTYPES(at::Half)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    bgemm_tunable<at::Half>(CUDABLAS_BGEMM_ARGS(at::Half));
  }
  else {
    bgemm_internal<at::Half>(CUDABLAS_BGEMM_ARGS(at::Half));
  }
}

template <>
void bgemm<at::BFloat16>(CUDABLAS_BGEMM_ARGTYPES(at::BFloat16)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    bgemm_tunable<at::BFloat16>(CUDABLAS_BGEMM_ARGS(at::BFloat16));
  }
  else {
    bgemm_internal<at::BFloat16>(CUDABLAS_BGEMM_ARGS(at::BFloat16));
  }
}

template <typename Dtype>
inline void gemm_internal_hipblaslt(CUDABLAS_GEMM_ARGTYPES(Dtype)) {
  // forward to bgemm implementation but set strides and batches to 0
  bgemm_internal_hipblaslt(transa, transb, m, n, k, alpha, a, lda, 0, b, ldb, 0, beta, c, ldc, 0, 0);
}

template <typename Dtype>
inline void gemm_internal_hipblas(CUDABLAS_GEMM_ARGTYPES(Dtype)) {
  AT_ERROR("at::zoom::blas::gemm_internal_hipblas: not implemented for ", typeid(Dtype).name());
}

template <>
void gemm_internal_hipblas<double>(CUDABLAS_GEMM_ARGTYPES(double)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  GEMM_CHECK_ARGVALUES(double);
  TORCH_HIPBLAS_CHECK(hipblasDgemm(
      handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc));
}

template <>
void gemm_internal_hipblas<float>(CUDABLAS_GEMM_ARGTYPES(float)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  GEMM_CHECK_ARGVALUES(float);
  TORCH_HIPBLAS_CHECK(hipblasSgemm(
      handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc));
}

template <>
void gemm_internal_hipblas<c10::complex<double>>(CUDABLAS_GEMM_ARGTYPES(c10::complex<double>)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  GEMM_CHECK_ARGVALUES(c10::complex<double>);
  TORCH_HIPBLAS_CHECK(hipblasZgemm(
      handle, opa, opb, m, n, k, reinterpret_cast<const hipDoubleComplex*>(&alpha), reinterpret_cast<const hipDoubleComplex*>(a),
      lda, reinterpret_cast<const hipDoubleComplex*>(b), ldb, reinterpret_cast<const hipDoubleComplex*>(&beta),
      reinterpret_cast<hipDoubleComplex*>(c), ldc));
}

template <>
void gemm_internal_hipblas<c10::complex<float>>(CUDABLAS_GEMM_ARGTYPES(c10::complex<float>)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  GEMM_CHECK_ARGVALUES(c10::complex<float>);
  TORCH_HIPBLAS_CHECK(hipblasCgemm(
      handle, opa, opb, m, n, k, reinterpret_cast<const hipComplex*>(&alpha), reinterpret_cast<const hipComplex*>(a),
      lda, reinterpret_cast<const hipComplex*>(b), ldb, reinterpret_cast<const hipComplex*>(&beta),
      reinterpret_cast<hipComplex*>(c), ldc));
}

template <>
void gemm_internal_hipblas<at::Half>(CUDABLAS_GEMM_ARGTYPES(at::Half)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  float falpha = alpha;
  float fbeta = beta;
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  GEMM_CHECK_ARGVALUES(at::Half);

  int flag = 0;
#if USE_GEMM_FLAGS_FP16_ALT_IMPL
  flag = at::ROCmBackwardPassGuard::is_backward_pass() ? rocblas_gemm_flags_fp16_alt_impl : 0;
#endif
  TORCH_HIPBLAS_CHECK(rocBLASStatusToHIPStatus(rocblas_gemm_ex(
      (rocblas_handle)handle,
      hipOperationToRocOperation(opa),
      hipOperationToRocOperation(opb),
      m,
      n,
      k,
      &falpha,
      a,
      rocblas_datatype_f16_r,
      lda,
      b,
      rocblas_datatype_f16_r,
      ldb,
      &fbeta,
      c,
      rocblas_datatype_f16_r,
      ldc,
      c,
      rocblas_datatype_f16_r,
      ldc,
      rocblas_datatype_f32_r,
      rocblas_gemm_algo_standard,
      0,
      flag)));

}

template <>
void gemm_internal_hipblas<at::BFloat16>(CUDABLAS_GEMM_ARGTYPES(at::BFloat16)) {
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t opa = _hipblasOpFromChar(transa);
  hipblasOperation_t opb = _hipblasOpFromChar(transb);
  float falpha = alpha;
  float fbeta = beta;
  _hipblasAdjustLdLevel3(transa, transb, m, n, k, &lda, &ldb, &ldc);
  GEMM_CHECK_ARGVALUES(at::BFloat16);
#ifdef HIPBLAS_V2
  auto compute_type = HIPBLAS_COMPUTE_32F;
#else
  auto compute_type = HIP_R_16BF;
#endif
  TORCH_HIPBLAS_CHECK(hipblasSetMathMode(handle, hipblas_flags));
  TORCH_HIPBLAS_CHECK(hipblasGemmEx(
      handle,
      opa,
      opb,
      m,
      n,
      k,
      &falpha,
      a,
      HIP_R_16BF,
      lda,
      b,
      HIP_R_16BF,
      ldb,
      &fbeta,
      c,
      HIP_R_16BF,
      ldc,
      compute_type,
      HIPBLAS_GEMM_DEFAULT));
  TORCH_HIPBLAS_CHECK(hipblasSetMathMode(handle, HIPBLAS_DEFAULT_MATH));
}

template <>
void gemm_internal<double>(CUDABLAS_GEMM_ARGTYPES(double))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    // hipblaslt does not support double gemm yet
    gemm_internal_hipblas<double>(CUDABLAS_GEMM_ARGS(double));
  }
  else {
    gemm_internal_hipblas<double>(CUDABLAS_GEMM_ARGS(double));
  }
}

template <>
void gemm_internal<float>(CUDABLAS_GEMM_ARGTYPES(float))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    #ifdef DISABLE_HIPBLASLT
    TORCH_WARN_DISABLE_HIPBLASLT
    gemm_internal_hipblas<float>(CUDABLAS_GEMM_ARGS(float));
    #else
    gemm_internal_hipblaslt<float>(CUDABLAS_GEMM_ARGS(float));
    #endif
  }
  else {
    gemm_internal_hipblas<float>(CUDABLAS_GEMM_ARGS(float));
  }
}

template <>
void gemm_internal<c10::complex<double>>(CUDABLAS_GEMM_ARGTYPES(c10::complex<double>))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    // hipblaslt does not support complex gemm yet
    gemm_internal_hipblas<c10::complex<double>>(CUDABLAS_GEMM_ARGS(c10::complex<double>));
  }
  else {
    gemm_internal_hipblas<c10::complex<double>>(CUDABLAS_GEMM_ARGS(c10::complex<double>));
  }
}

template <>
void gemm_internal<c10::complex<float>>(CUDABLAS_GEMM_ARGTYPES(c10::complex<float>))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    // hipblaslt does not support complex gemm yet
    gemm_internal_hipblas<c10::complex<float>>(CUDABLAS_GEMM_ARGS(c10::complex<float>));
  }
  else {
    gemm_internal_hipblas<c10::complex<float>>(CUDABLAS_GEMM_ARGS(c10::complex<float>));
  }
}

template <>
void gemm_internal<at::Half>(CUDABLAS_GEMM_ARGTYPES(at::Half))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    #ifdef DISABLE_HIPBLASLT
    TORCH_WARN_DISABLE_HIPBLASLT
    gemm_internal_hipblas<at::Half>(CUDABLAS_GEMM_ARGS(at::Half));
    #else
    gemm_internal_hipblaslt<at::Half>(CUDABLAS_GEMM_ARGS(at::Half));
    #endif
  }
  else {
    gemm_internal_hipblas<at::Half>(CUDABLAS_GEMM_ARGS(at::Half));
  }
}

template <>
void gemm_internal<at::BFloat16>(CUDABLAS_GEMM_ARGTYPES(at::BFloat16))
{
  if (at::globalContext().blasPreferredBackend() == BlasBackend::Cublaslt) {
    #ifdef DISABLE_HIPBLASLT
    TORCH_WARN_DISABLE_HIPBLASLT
    gemm_internal_hipblas<at::BFloat16>(CUDABLAS_GEMM_ARGS(at::BFloat16));
    #else
    gemm_internal_hipblaslt<at::BFloat16>(CUDABLAS_GEMM_ARGS(at::BFloat16));
    #endif
  }
  else {
    gemm_internal_hipblas<at::BFloat16>(CUDABLAS_GEMM_ARGS(at::BFloat16));
  }
}

template <typename DType>
inline void gemm_tunable(CUDABLAS_GEMM_ARGTYPES(DType)) {
  tunable::GemmParams<DType> params;
  params.transa = transa;
  params.transb = transb;
  params.m = m;
  params.n = n;
  params.k = k;
  params.alpha = alpha;
  params.a = a;
  params.lda = lda;
  params.b = b;
  params.ldb = ldb;
  params.beta = beta;
  params.c = c;
  params.ldc = ldc;

  bool transa_ = ((transa != 'n') && (transa != 'N'));
  bool transb_ = ((transb != 'n') && (transb != 'N'));

  if (transa_ && transb_) {
    static tunable::GemmTunableOp<DType, tunable::BlasOp::T, tunable::BlasOp::T> gemm{};
    gemm(&params);
  }
  else if (transa_ && !transb_) {
    static tunable::GemmTunableOp<DType, tunable::BlasOp::T, tunable::BlasOp::N> gemm{};
    gemm(&params);
  }
  else if (!transa_ && transb_) {
    static tunable::GemmTunableOp<DType, tunable::BlasOp::N, tunable::BlasOp::T> gemm{};
    gemm(&params);
  }
  else if (!transa_ && !transb_) {
    static tunable::GemmTunableOp<DType, tunable::BlasOp::N, tunable::BlasOp::N> gemm{};
    gemm(&params);
  }
  else {
    TORCH_CHECK(false, "unreachable");
  }
}

template <>
void gemm<double>(CUDABLAS_GEMM_ARGTYPES(double)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    gemm_tunable<double>(CUDABLAS_GEMM_ARGS(double));
  }
  else {
    gemm_internal<double>(CUDABLAS_GEMM_ARGS(double));
  }
}

template <>
void gemm<float>(CUDABLAS_GEMM_ARGTYPES(float)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    gemm_tunable<float>(CUDABLAS_GEMM_ARGS(float));
  }
  else {
    gemm_internal<float>(CUDABLAS_GEMM_ARGS(float));
  }
}

template <>
void gemm<c10::complex<double>>(CUDABLAS_GEMM_ARGTYPES(c10::complex<double>)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    gemm_tunable<c10::complex<double>>(CUDABLAS_GEMM_ARGS(c10::complex<double>));
  }
  else {
    gemm_internal<c10::complex<double>>(CUDABLAS_GEMM_ARGS(c10::complex<double>));
  }
}

template <>
void gemm<c10::complex<float>>(CUDABLAS_GEMM_ARGTYPES(c10::complex<float>)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    gemm_tunable<c10::complex<float>>(CUDABLAS_GEMM_ARGS(c10::complex<float>));
  }
  else {
    gemm_internal<c10::complex<float>>(CUDABLAS_GEMM_ARGS(c10::complex<float>));
  }
}

template <>
void gemm<at::Half>(CUDABLAS_GEMM_ARGTYPES(at::Half)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    gemm_tunable<at::Half>(CUDABLAS_GEMM_ARGS(at::Half));
  }
  else {
    gemm_internal<at::Half>(CUDABLAS_GEMM_ARGS(at::Half));
  }
}

template <>
void gemm<at::BFloat16>(CUDABLAS_GEMM_ARGTYPES(at::BFloat16)) {
  auto tuning_ctx = at::zoom::tunable::getTuningContext();
  if (tuning_ctx->IsTunableOpEnabled()) {
    gemm_tunable<at::BFloat16>(CUDABLAS_GEMM_ARGS(at::BFloat16));
  }
  else {
    gemm_internal<at::BFloat16>(CUDABLAS_GEMM_ARGS(at::BFloat16));
  }
}


template <typename Dtype>
void gemm_and_bias(
    bool transpose_mat1,
    bool transpose_mat2,
    int64_t m,
    int64_t n,
    int64_t k,
    at::opmath_type<Dtype> alpha_val,
    const Dtype* mat1_ptr,
    int64_t mat1_ld,
    const Dtype* mat2_ptr,
    int64_t mat2_ld,
    const Dtype* bias,
    Dtype* result_ptr,
    int64_t result_ld,
    GEMMAndBiasActivationEpilogue activation) {
  #ifdef DISABLE_HIPBLASLT
  TORCH_CHECK_DISABLE_HIPBLAS_LT
  #else
  using opmath_t = at::opmath_type<Dtype>;
  opmath_t beta_val = 0; // bias is added in epilogue

  hipDataType abcType = HIP_R_32F;
  hipblasComputeType_t computeType = HIPBLAS_COMPUTE_32F;
  hipDataType scaleType = HIP_R_32F;
  if constexpr (std::is_same_v<Dtype, double>) {
    abcType = HIP_R_64F;
    computeType = HIPBLAS_COMPUTE_64F;
    scaleType = HIP_R_64F;
  } else if constexpr (std::is_same_v<Dtype, float>) {
    abcType = HIP_R_32F;
  } else if constexpr (std::is_same_v<Dtype, at::Half>) {
    abcType = HIP_R_16F;
  } else if constexpr (std::is_same_v<Dtype, at::BFloat16>) {
    abcType = HIP_R_16BF;
  }

  CuBlasLtMatmulDescriptor computeDesc(computeType, scaleType);
  hipblasOperation_t transa = transpose_mat1 ? HIPBLAS_OP_T : HIPBLAS_OP_N;
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSA, transa);
  hipblasOperation_t transb = transpose_mat2 ? HIPBLAS_OP_T : HIPBLAS_OP_N;
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSB, transb);
  hipblasLtEpilogue_t epilogue = HIPBLASLT_EPILOGUE_BIAS;
  if (activation == GEMMAndBiasActivationEpilogue::RELU) {
    epilogue = HIPBLASLT_EPILOGUE_RELU_BIAS;
  } else if (activation == GEMMAndBiasActivationEpilogue::GELU) {
#if TORCH_HIP_VERSION >= 11040 || defined(USE_ROCM)
    epilogue = HIPBLASLT_EPILOGUE_GELU_BIAS;
#endif
  }

  if (bias != nullptr) {
    computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_EPILOGUE, epilogue);
    computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_BIAS_POINTER, bias);
  }

  CuBlasLtMatrixLayout Adesc(abcType, m, k, mat1_ld, transpose_mat1);
  CuBlasLtMatrixLayout Bdesc(abcType, k, n, mat2_ld, transpose_mat2);
  CuBlasLtMatrixLayout Cdesc(abcType, m, n, result_ld);

  CuBlasLtMatmulPreference preference;
  // See https://github.com/pytorch/pytorch/issues/73328 for reasoning behind
  // setting this to 1M.
  size_t workspaceSize = _getWorkspaceSize();
  preference.setAttribute(HIPBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES, workspaceSize);

  auto& allocator = *::c10::zoom::ZoomCachingAllocator::get();
  auto workspace = allocator.allocate(workspaceSize);
  TORCH_CHECK(workspace.get() != nullptr, "OOM trying to allocate workspace for hipblaslt");

  hipblasLtMatmulHeuristicResult_t heuristicResult = {};
  int returnedResult = 0;
  hipblasLtHandle_t ltHandle = at::zoom::getCurrentHIPBlasLtHandle();
  TORCH_HIPBLAS_CHECK(hipblasLtMatmulAlgoGetHeuristic(
      ltHandle,
      computeDesc.descriptor(),
      Adesc.descriptor(),
      Bdesc.descriptor(),
      Cdesc.descriptor(),
      Cdesc.descriptor(),
      preference.descriptor(),
      1,
      &heuristicResult,
      &returnedResult));
  if (returnedResult == 0) {
    TORCH_HIPBLAS_CHECK(HIPBLAS_STATUS_NOT_SUPPORTED);
  }

  hipblasStatus_t hipblasStatus = hipblasLtMatmul(
      ltHandle,
      computeDesc.descriptor(),
      &alpha_val,
      mat1_ptr,
      Adesc.descriptor(),
      mat2_ptr,
      Bdesc.descriptor(),
      &beta_val,
      result_ptr,
      Cdesc.descriptor(),
      result_ptr,
      Cdesc.descriptor(),
      &heuristicResult.algo,
      workspace.mutable_get(),
      workspaceSize,
      c10::zoom::GetCurrentZoomStream());
  TORCH_CHECK(
      hipblasStatus == HIPBLAS_STATUS_SUCCESS,
      "CUDA error: ",
      at::zoom::blas::_hipblasGetErrorEnum(hipblasStatus),
      " when calling hipblasLtMatmul with transpose_mat1 ",
      transpose_mat1,
      " transpose_mat2 ",
      transpose_mat2,
      " m ",
      m,
      " n ",
      n,
      " k ",
      k,
      " mat1_ld ",
      mat1_ld,
      " mat2_ld ",
      mat2_ld,
      " result_ld ",
      result_ld,
      " abcType ",
      abcType,
      " computeType ",
      computeType,
      " scaleType ",
      scaleType);
  #endif
}

template void gemm_and_bias(
    bool transpose_mat1,
    bool transpose_mat2,
    int64_t m,
    int64_t n,
    int64_t k,
    at::opmath_type<double> alpha_val,
    const double* mat1_ptr,
    int64_t mat1_ld,
    const double* mat2_ptr,
    int64_t mat2_ld,
    const double* bias,
    double* result_ptr,
    int64_t result_ld,
    GEMMAndBiasActivationEpilogue activation);

template void gemm_and_bias(
    bool transpose_mat1,
    bool transpose_mat2,
    int64_t m,
    int64_t n,
    int64_t k,
    at::opmath_type<float> alpha_val,
    const float* mat1_ptr,
    int64_t mat1_ld,
    const float* mat2_ptr,
    int64_t mat2_ld,
    const float* bias,
    float* result_ptr,
    int64_t result_ld,
    GEMMAndBiasActivationEpilogue activation);

template void gemm_and_bias(
    bool transpose_mat1,
    bool transpose_mat2,
    int64_t m,
    int64_t n,
    int64_t k,
    at::opmath_type<at::Half> alpha_val,
    const at::Half* mat1_ptr,
    int64_t mat1_ld,
    const at::Half* mat2_ptr,
    int64_t mat2_ld,
    const at::Half* bias,
    at::Half* result_ptr,
    int64_t result_ld,
    GEMMAndBiasActivationEpilogue activation);

template void gemm_and_bias(
    bool transpose_mat1,
    bool transpose_mat2,
    int64_t m,
    int64_t n,
    int64_t k,
    at::opmath_type<at::BFloat16> alpha_val,
    const at::BFloat16* mat1_ptr,
    int64_t mat1_ld,
    const at::BFloat16* mat2_ptr,
    int64_t mat2_ld,
    const at::BFloat16* bias,
    at::BFloat16* result_ptr,
    int64_t result_ld,
    GEMMAndBiasActivationEpilogue activation);

void scaled_gemm(
    char transa,
    char transb,
    int64_t m,
    int64_t n,
    int64_t k,
    const void* mat1_ptr,
    const void* mat1_scale_ptr,
    int64_t mat1_ld,
    ScalarType mat1_dtype,
    const void* mat2_ptr,
    const void* mat2_scale_ptr,
    int64_t mat2_ld,
    ScalarType mat2_dtype,
    const void* bias_ptr,
    ScalarType bias_dtype,
    void* result_ptr,
    const void *result_scale_ptr,
    int64_t result_ld,
    ScalarType result_dtype,
    void* amax_ptr,
    bool use_fast_accum) {
#ifdef DISABLE_HIPBLASLT
  TORCH_CHECK_DISABLE_HIPBLAS_LT
#else
#if TORCH_HIP_VERSION >= 11080 || defined(USE_ROCM)
  const auto computeType = HIPBLAS_COMPUTE_32F;
  const auto scaleType = HIP_R_32F;
  const int8_t fastAccuMode = use_fast_accum ? 1 : 0;
  const float alpha_val = 1.0;
  const float beta_val = 0.0;
  CuBlasLtMatmulDescriptor computeDesc(computeType, scaleType);
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSA, _hipblasOpFromChar(transa));
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSB, _hipblasOpFromChar(transb));
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_A_SCALE_POINTER, mat1_scale_ptr);
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_B_SCALE_POINTER, mat2_scale_ptr);
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_D_SCALE_POINTER, result_scale_ptr);
#if ROCM_VERSION >= 60200
  // Amax support in ROCm as of 6.2
  if (isFloat8Type(result_dtype)) {
    computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_AMAX_D_POINTER, amax_ptr);
  }
#endif

  CuBlasLtMatrixLayout Adesc(ScalarTypeToCudaDataType(mat1_dtype), m, k, mat1_ld, transa == 't');
  CuBlasLtMatrixLayout Bdesc(ScalarTypeToCudaDataType(mat2_dtype), k, n, mat2_ld, transb == 't');

  // Cdesc is unused, beta is 0. But hipblaslt needs this set to something reasonable.
  CuBlasLtMatrixLayout Cdesc(ScalarTypeToCudaDataType(result_dtype), m, n, result_ld);

  CuBlasLtMatrixLayout Ddesc(ScalarTypeToCudaDataType(result_dtype), m, n, result_ld);
  if (bias_ptr) {
    computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_BIAS_POINTER, bias_ptr);
    computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_EPILOGUE, HIPBLASLT_EPILOGUE_BIAS);
    computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_BIAS_DATA_TYPE, ScalarTypeToCudaDataType(bias_dtype));
  }
  size_t workspaceSize = _getWorkspaceSize();
  auto& allocator = *::c10::zoom::ZoomCachingAllocator::get();
  auto workspace = allocator.allocate(workspaceSize);
  TORCH_CHECK(workspace.get() != nullptr, "OOM trying to allocate workspace for hipblaslt");

  CuBlasLtMatmulPreference preference;
  preference.setAttribute(HIPBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES, workspaceSize);
  hipblasLtMatmulHeuristicResult_t heuristicResult = {};
  int returnedResult = 0;
  hipblasLtHandle_t ltHandle = at::zoom::getCurrentHIPBlasLtHandle();
  TORCH_HIPBLAS_CHECK(hipblasLtMatmulAlgoGetHeuristic(
      ltHandle,
      computeDesc.descriptor(),
      Adesc.descriptor(),
      Bdesc.descriptor(),
      Cdesc.descriptor(),
      Ddesc.descriptor(),
      preference.descriptor(),
      1,
      &heuristicResult,
      &returnedResult));
  if (returnedResult == 0) {

    // hipblaslt might be able to recover by returning all algos
    std::vector<hipblasLtMatmulHeuristicResult_t> all_algos;
    TORCH_HIPBLAS_CHECK(hipblaslt_ext::getAllAlgos(
        ltHandle,
        hipblaslt_ext::GemmType::HIPBLASLT_GEMM,
        _hipblasOpFromChar(transa),
        _hipblasOpFromChar(transb),
        ScalarTypeToCudaDataType(mat1_dtype),
        ScalarTypeToCudaDataType(mat2_dtype),
        // C is nullptr and beta=0, so set to something reasonable. See above.
        //ScalarTypeToCudaDataType(bias_dtype),
        ScalarTypeToCudaDataType(result_dtype),
        ScalarTypeToCudaDataType(result_dtype),
        HIPBLAS_COMPUTE_32F,
        all_algos));
    if (all_algos.size() == 0) {
      TORCH_HIPBLAS_CHECK(HIPBLAS_STATUS_NOT_SUPPORTED);
    }
    // pick first valid solution
    bool found = false;
    for (size_t i = 0; i < all_algos.size(); i++) {
        size_t ret_workspace_size = 0;
        auto is_valid_status = hipblaslt_ext::matmulIsAlgoSupported(
                ltHandle,
                computeDesc.descriptor(),
                &alpha_val,
                Adesc.descriptor(),
                Bdesc.descriptor(),
                &beta_val,
                Cdesc.descriptor(),
                Ddesc.descriptor(),
                all_algos[i].algo,
                ret_workspace_size);
        if (is_valid_status == HIPBLAS_STATUS_SUCCESS) {
            if (ret_workspace_size <= workspaceSize) {
                heuristicResult = all_algos[i];
                found = true;
                break;
            }
        }
    }
    TORCH_CHECK(found, "could not find valid hipblaslt solution");
  }
  hipblasStatus_t hipblasStatus = hipblasLtMatmul(
      ltHandle,
      computeDesc.descriptor(),
      &alpha_val,
      mat1_ptr,
      Adesc.descriptor(),
      mat2_ptr,
      Bdesc.descriptor(),
      &beta_val,
      result_ptr, // unused, since beta_val is 0, but hipblaslt can't handle nullptr
      Cdesc.descriptor(),
      result_ptr,
      Ddesc.descriptor(),
      &heuristicResult.algo,
      workspace.mutable_get(),
      workspaceSize,
      c10::zoom::GetCurrentZoomStream());
  TORCH_CHECK(
      hipblasStatus == HIPBLAS_STATUS_SUCCESS,
      "CUDA error: ",
      at::zoom::blas::_hipblasGetErrorEnum(hipblasStatus),
      " when calling hipblasLtMatmul with transpose_mat1 ",
      transa,
      " transpose_mat2 ",
      transb,
      " m ",
      m,
      " n ",
      n,
      " k ",
      k,
      " mat1_ld ",
      mat1_ld,
      " mat2_ld ",
      mat2_ld,
      " result_ld ",
      result_ld,
      " computeType ",
      computeType,
      " scaleType ",
      scaleType);
  return;
#endif // TORCH_HIP_VERSION >= 11080 || defined(USE_ROCM)
  TORCH_CHECK(false, "scaled_gemm is only supported for CUDA 11.8 and above");
#endif
}

void int8_gemm(
    bool transpose_mat1,
    bool transpose_mat2,
    int64_t m,
    int64_t n,
    int64_t k,
    const int8_t* mat1_ptr,
    int64_t mat1_ld,
    const int8_t* mat2_ptr,
    int64_t mat2_ld,
    int32_t* result_ptr,
    int64_t result_ld) {
#ifdef DISABLE_HIPBLASLT
  TORCH_CHECK_DISABLE_HIPBLAS_LT
#else
  hipblasComputeType_t computeType = HIPBLAS_COMPUTE_32I;
  hipDataType scaleType = HIP_R_32I;

  hipDataType abType = HIP_R_8I;
  hipDataType cType = HIP_R_32I;

  CuBlasLtMatmulDescriptor computeDesc(computeType, scaleType);
  hipblasOperation_t transa = transpose_mat1 ? HIPBLAS_OP_T : HIPBLAS_OP_N;
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSA, transa);
  hipblasOperation_t transb = transpose_mat2 ? HIPBLAS_OP_T : HIPBLAS_OP_N;
  computeDesc.setAttribute(HIPBLASLT_MATMUL_DESC_TRANSB, transb);


  CuBlasLtMatrixLayout Adesc(abType, m, k, mat1_ld, transpose_mat1);
  CuBlasLtMatrixLayout Bdesc(abType, k, n, mat2_ld, transpose_mat2);
  CuBlasLtMatrixLayout Cdesc(cType, m, n, result_ld);

  // hipblas team: alpha and beta need to be the same dtype as of scaleType
  at::opmath_type<int32_t> alpha_val = 1;
  int32_t beta_val = 0;
  hipblasLtHandle_t ltHandle = at::zoom::getCurrentHIPBlasLtHandle();

  CuBlasLtMatmulPreference preference;
  size_t workspaceSize = _getWorkspaceSize();
  preference.setAttribute(HIPBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES, workspaceSize);
  auto& allocator = *::c10::zoom::ZoomCachingAllocator::get();
  auto workspace = allocator.allocate(workspaceSize);
  hipblasLtMatmulHeuristicResult_t heuristicResult = {};
  int returnedResult = 0;
  TORCH_HIPBLAS_CHECK(hipblasLtMatmulAlgoGetHeuristic(
      ltHandle,
      computeDesc.descriptor(),
      Adesc.descriptor(),
      Bdesc.descriptor(),
      Cdesc.descriptor(),
      Cdesc.descriptor(),
      preference.descriptor(),
      1,
      &heuristicResult,
      &returnedResult));
  if (returnedResult == 0) {
    TORCH_HIPBLAS_CHECK(HIPBLAS_STATUS_NOT_SUPPORTED);
  }


  hipblasStatus_t hipblasStatus = hipblasLtMatmul(
      ltHandle,
      computeDesc.descriptor(),
      &alpha_val,
      mat1_ptr,
      Adesc.descriptor(),
      mat2_ptr,
      Bdesc.descriptor(),
      &beta_val,
      result_ptr,
      Cdesc.descriptor(),
      result_ptr,
      Cdesc.descriptor(),
      &heuristicResult.algo,
      workspace.mutable_get(),
      workspaceSize,
      c10::zoom::GetCurrentZoomStream());
  TORCH_CHECK(
      hipblasStatus == HIPBLAS_STATUS_SUCCESS,
      "CUDA error: ",
      at::zoom::blas::_hipblasGetErrorEnum(hipblasStatus),
      " when calling hipblasLtMatmul with transpose_mat1 ",
      transpose_mat1,
      " transpose_mat2 ",
      transpose_mat2,
      " m ",
      m,
      " n ",
      n,
      " k ",
      k,
      " mat1_ld ",
      mat1_ld,
      " mat2_ld ",
      mat2_ld,
      " result_ld ",
      result_ld,
      " abType ",
      abType,
      " cType ",
      cType,
      " computeType ",
      computeType,
      " scaleType ",
      scaleType);
  #endif
}

template <>
void trsm<float>(CUDABLAS_TRSM_ARGTYPES(float)) {
  TORCH_HIPBLAS_CHECK(hipblasStrsm(
      handle, side, uplo, trans, diag, m, n, alpha, A, lda, B, ldb));
}

template <>
void trsm<double>(CUDABLAS_TRSM_ARGTYPES(double)) {
  TORCH_HIPBLAS_CHECK(hipblasDtrsm(
      handle, side, uplo, trans, diag, m, n, alpha, A, lda, B, ldb));
}

template <>
void trsm<c10::complex<float>>(CUDABLAS_TRSM_ARGTYPES(c10::complex<float>)) {
  TORCH_HIPBLAS_CHECK(hipblasCtrsm(
      handle,
      side,
      uplo,
      trans,
      diag,
      m,
      n,
      reinterpret_cast<const hipComplex*>(alpha),
      reinterpret_cast<const hipComplex*>(A),
      lda,
      reinterpret_cast<hipComplex*>(B),
      ldb));
}

template <>
void trsm<c10::complex<double>>(CUDABLAS_TRSM_ARGTYPES(c10::complex<double>)) {
  TORCH_HIPBLAS_CHECK(hipblasZtrsm(
      handle,
      side,
      uplo,
      trans,
      diag,
      m,
      n,
      reinterpret_cast<const hipDoubleComplex*>(alpha),
      reinterpret_cast<const hipDoubleComplex*>(A),
      lda,
      reinterpret_cast<hipDoubleComplex*>(B),
      ldb));
}

template <>
void trsmBatched<float>(CUDABLAS_TRSM_BATCHED_ARGTYPES(float)) {
  TORCH_HIPBLAS_CHECK(hipblasStrsmBatched(
      handle,
      side,
      uplo,
      trans,
      diag,
      m,
      n,
      alpha,
      A,
      lda,
      B,
      ldb,
      batchCount));
}

template <>
void trsmBatched<double>(CUDABLAS_TRSM_BATCHED_ARGTYPES(double)) {
  TORCH_HIPBLAS_CHECK(hipblasDtrsmBatched(
      handle,
      side,
      uplo,
      trans,
      diag,
      m,
      n,
      alpha,
      A,
      lda,
      B,
      ldb,
      batchCount));
}

template <>
void trsmBatched<c10::complex<float>>(
    CUDABLAS_TRSM_BATCHED_ARGTYPES(c10::complex<float>)) {
  TORCH_HIPBLAS_CHECK(hipblasCtrsmBatched(
      handle,
      side,
      uplo,
      trans,
      diag,
      m,
      n,
      reinterpret_cast<const hipComplex*>(alpha),
      reinterpret_cast<hipComplex**>(A),
      lda,
      reinterpret_cast<hipComplex**>(B),
      ldb,
      batchCount));
}

template <>
void trsmBatched<c10::complex<double>>(
    CUDABLAS_TRSM_BATCHED_ARGTYPES(c10::complex<double>)) {
  TORCH_HIPBLAS_CHECK(hipblasZtrsmBatched(
      handle,
      side,
      uplo,
      trans,
      diag,
      m,
      n,
      reinterpret_cast<const hipDoubleComplex*>(alpha),
      reinterpret_cast<hipDoubleComplex**>(A),
      lda,
      reinterpret_cast<hipDoubleComplex**>(B),
      ldb,
      batchCount));
}

/* LEVEL 2 BLAS FUNCTIONS */

#define GEMV_CHECK_ARGVALUES(Dtype)           \
  do {                                        \
    CUDABLAS_NONNEGINT_CHECK(gemv<Dtype>, m); \
    CUDABLAS_NONNEGINT_CHECK(gemv<Dtype>, n); \
    CUDABLAS_POSINT_CHECK(gemv<Dtype>, lda);  \
    CUDABLAS_POSINT_CHECK(gemv<Dtype>, incx); \
    CUDABLAS_POSINT_CHECK(gemv<Dtype>, incy); \
  } while (0)

template <>
void gemv<c10::complex<double>>(CUDABLAS_GEMV_ARGTYPES(c10::complex<double>)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t op = _hipblasOpFromChar(trans);
  _hipblasAdjustLdLevel2(m, n, &lda);
  GEMV_CHECK_ARGVALUES(c10::complex<double>);
  TORCH_HIPBLAS_CHECK(
      hipblasZgemv(handle, op, m, n, reinterpret_cast<const hipDoubleComplex*>(&alpha), reinterpret_cast<const hipDoubleComplex*>(a),
      lda, reinterpret_cast<const hipDoubleComplex*>(x), incx, reinterpret_cast<const hipDoubleComplex*>(&beta),
      reinterpret_cast<hipDoubleComplex*>(y), incy));
}

template <>
void gemv<c10::complex<float>>(CUDABLAS_GEMV_ARGTYPES(c10::complex<float>)) {
  // gemv is bw bound, and does not benefit from TF32. But the precision
  // loss still happens on TF32. So we disable it here.
  NoTF32Guard disable_tf32;
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t op = _hipblasOpFromChar(trans);
  _hipblasAdjustLdLevel2(m, n, &lda);
  GEMV_CHECK_ARGVALUES(c10::complex<float>);
  TORCH_HIPBLAS_CHECK(
      hipblasCgemv(handle, op, m, n, reinterpret_cast<const hipComplex*>(&alpha), reinterpret_cast<const hipComplex*>(a),
      lda, reinterpret_cast<const hipComplex*>(x), incx, reinterpret_cast<const hipComplex*>(&beta),
      reinterpret_cast<hipComplex*>(y), incy));
}

template <>
void gemv<double>(CUDABLAS_GEMV_ARGTYPES(double)) {
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t op = _hipblasOpFromChar(trans);
  _hipblasAdjustLdLevel2(m, n, &lda);
  GEMV_CHECK_ARGVALUES(double);
  TORCH_HIPBLAS_CHECK(
      hipblasDgemv(handle, op, m, n, &alpha, a, lda, x, incx, &beta, y, incy));
}

template <>
void gemv<float>(CUDABLAS_GEMV_ARGTYPES(float)) {
  // gemv is bw bound, and does not benefit from TF32. But the precision
  // loss still happens on TF32. So we disable it here.
  NoTF32Guard disable_tf32;
  // See Note [Writing Nondeterministic Operations]
  globalContext().alertCuBLASConfigNotDeterministic();
  hipblasHandle_t handle = at::zoom::getCurrentHIPBlasHandle();
  hipblasOperation_t op = _hipblasOpFromChar(trans);
  _hipblasAdjustLdLevel2(m, n, &lda);
  GEMV_CHECK_ARGVALUES(float);
  TORCH_HIPBLAS_CHECK(
      hipblasSgemv(handle, op, m, n, &alpha, a, lda, x, incx, &beta, y, incy));
}

template <>
void gemv<at::Half>(CUDABLAS_GEMV_ARGTYPES(at::Half)) {
  // In general, hipblas regards matrices as column-major.
  // The hipblasS/Dgemv usages in cuda::blas::gemv<float>/<double> above
  // require that external blas::gemv callers obey the following convention:
  //
  // If "a" is row-major with shape (output, summed) in blas::gemv's caller,
  // caller interprets it as column-major with shape (summed, output), passes
  // summed and output respectively to our local vars m, n, and requests that hipblas
  // internally transpose ("trans") the column-major interpretation of a.
  //
  // There's no such thing as "hipblasHalfgemv", so here we hack gemv with a gemm.
  // However, we must allow the same calling convention, because the caller shouldn't
  // have to swap args based on whether it's calling blas::gemv<at::Half> or <float>.

  bool trans_bool = (_hipblasOpFromChar(trans) != HIPBLAS_OP_N);
  if (trans_bool) {
    std::swap(m, n);
  }
  // After swap, local vars m, n contain the output and summed sizes respectively,
  // regardless of whether "a" was row-major or column-major in gemv<>'s caller.

  // To handle the possibility incy > 1, interprets vector y as column-major matrix with one row
  // (shape (1, output)) and leading dim incy.
  // trans(a)*x would compute a matrix with one column (shape (output, 1)) which wouldn't match y.
  // So instead, we interpret x similarly to y, as a column-major matrix with one row
  // (shape (1, summed)) and leading dim incx.  The gemm then carries out x*transpose(trans(a)) to
  // produce a matrix with one row (shape (1, output)), matching y.
  char trans_flipped = (trans_bool ? 'n' : 't');
  gemm<at::Half>(
      'n', trans_flipped, 1, m, n, alpha, x, incx, a, lda, beta, y, incy);
}

template <>
void gemv<at::BFloat16>(CUDABLAS_GEMV_ARGTYPES(at::BFloat16)) {
  bool trans_bool = (_hipblasOpFromChar(trans) != HIPBLAS_OP_N);
  if (trans_bool) {
    std::swap(m, n);
  }
  char trans_flipped = (trans_bool ? 'n' : 't');
  gemm<at::BFloat16>(
      'n', trans_flipped, 1, m, n, alpha, x, incx, a, lda, beta, y, incy);
}

/* LEVEL 1 BLAS FUNCTIONS */

template <>
void dot<double>(CUDABLAS_DOT_ARGTYPES(double)) {
  TORCH_HIPBLAS_CHECK(hipblasDdot(handle, n, x, incx, y, incy, result));
}

template <>
void dot<float>(CUDABLAS_DOT_ARGTYPES(float)) {
  TORCH_HIPBLAS_CHECK(hipblasSdot(handle, n, x, incx, y, incy, result));
}

template <>
void dot<c10::complex<double>>(CUDABLAS_DOT_ARGTYPES(c10::complex<double>)) {
  TORCH_HIPBLAS_CHECK(hipblasZdotu(handle, n, reinterpret_cast<const hipDoubleComplex*>(x),
                                   incx, reinterpret_cast<const hipDoubleComplex*>(y), incy,
                                   reinterpret_cast<hipDoubleComplex*>(result)));
}

template <>
void dot<c10::complex<float>>(CUDABLAS_DOT_ARGTYPES(c10::complex<float>)) {
  TORCH_HIPBLAS_CHECK(hipblasCdotu(handle, n, reinterpret_cast<const hipComplex*>(x),
                                   incx, reinterpret_cast<const hipComplex*>(y), incy,
                                   reinterpret_cast<hipComplex*>(result)));
}

template <>
void dot<at::Half>(CUDABLAS_DOT_ARGTYPES(at::Half)) {
  TORCH_HIPBLAS_CHECK(hipblasDotEx(
      handle,
      n,
      x,
      HIP_R_16F,
      incx,
      y,
      HIP_R_16F,
      incy,
      result,
      HIP_R_16F,
      HIP_R_32F));
}

template <>
void dot<at::BFloat16>(CUDABLAS_DOT_ARGTYPES(at::BFloat16)) {
  TORCH_HIPBLAS_CHECK(hipblasDotEx(
      handle,
      n,
      x,
      HIP_R_16BF,
      incx,
      y,
      HIP_R_16BF,
      incy,
      result,
      HIP_R_16BF,
      HIP_R_32F));
}

template <>
void vdot<c10::complex<float>>(CUDABLAS_DOT_ARGTYPES(c10::complex<float>)) {
  TORCH_HIPBLAS_CHECK(hipblasCdotc(handle, n, reinterpret_cast<const hipComplex*>(x),
                                   incx, reinterpret_cast<const hipComplex*>(y), incy,
                                   reinterpret_cast<hipComplex*>(result)));
}

template <>
void vdot<c10::complex<double>>(CUDABLAS_DOT_ARGTYPES(c10::complex<double>)) {
  TORCH_HIPBLAS_CHECK(hipblasZdotc(handle, n, reinterpret_cast<const hipDoubleComplex*>(x),
                                   incx, reinterpret_cast<const hipDoubleComplex*>(y), incy,
                                   reinterpret_cast<hipDoubleComplex*>(result)));
}

template <>
void getrsBatched<float>(CUDABLAS_GETRS_ARGTYPES(float)) {
  TORCH_HIPBLAS_CHECK(hipblasSgetrsBatched(
      handle,
      trans,
      n,
      nrhs,
      dA_array,
      lda,
      ipiv_array,
      dB_array,
      ldb,
      info_array,
      batchsize));
}

template <>
void getrsBatched<double>(CUDABLAS_GETRS_ARGTYPES(double)) {
  TORCH_HIPBLAS_CHECK(hipblasDgetrsBatched(
      handle,
      trans,
      n,
      nrhs,
      dA_array,
      lda,
      ipiv_array,
      dB_array,
      ldb,
      info_array,
      batchsize));
}

template <>
void getrsBatched<c10::complex<float>>(CUDABLAS_GETRS_ARGTYPES(c10::complex<float>)) {
  TORCH_HIPBLAS_CHECK(hipblasCgetrsBatched(
      handle,
      trans,
      n,
      nrhs,
      reinterpret_cast<hipComplex**>(dA_array),
      lda,
      ipiv_array,
      reinterpret_cast<hipComplex**>(dB_array),
      ldb,
      info_array,
      batchsize));
}

template <>
void getrsBatched<c10::complex<double>>(CUDABLAS_GETRS_ARGTYPES(c10::complex<double>)) {
  TORCH_HIPBLAS_CHECK(hipblasZgetrsBatched(
      handle,
      trans,
      n,
      nrhs,
      reinterpret_cast<hipDoubleComplex**>(dA_array),
      lda,
      ipiv_array,
      reinterpret_cast<hipDoubleComplex**>(dB_array),
      ldb,
      info_array,
      batchsize));
}

template <>
void geqrfBatched<float>(CUDABLAS_GEQRF_BATCHED_ARGTYPES(float)) {
  TORCH_HIPBLAS_CHECK(hipblasSgeqrfBatched(
      handle, m, n, A_array, lda, tau_array, info, batchsize));
}

template <>
void geqrfBatched<double>(CUDABLAS_GEQRF_BATCHED_ARGTYPES(double)) {
  TORCH_HIPBLAS_CHECK(hipblasDgeqrfBatched(
      handle, m, n, A_array, lda, tau_array, info, batchsize));
}

template <>
void geqrfBatched<c10::complex<float>>(
    CUDABLAS_GEQRF_BATCHED_ARGTYPES(c10::complex<float>)) {
  TORCH_HIPBLAS_CHECK(hipblasCgeqrfBatched(
      handle,
      m,
      n,
      reinterpret_cast<hipComplex**>(A_array),
      lda,
      reinterpret_cast<hipComplex**>(tau_array),
      info,
      batchsize));
}

template <>
void geqrfBatched<c10::complex<double>>(
    CUDABLAS_GEQRF_BATCHED_ARGTYPES(c10::complex<double>)) {
  TORCH_HIPBLAS_CHECK(hipblasZgeqrfBatched(
      handle,
      m,
      n,
      reinterpret_cast<hipDoubleComplex**>(A_array),
      lda,
      reinterpret_cast<hipDoubleComplex**>(tau_array),
      info,
      batchsize));
}

template <>
void getrfBatched<double>(
    int n, double** dA_array, int ldda, int* ipiv_array, int* info_array, int batchsize) {
  auto handle = at::zoom::getCurrentHIPBlasHandle();
  TORCH_HIPBLAS_CHECK(hipblasDgetrfBatched(
      handle, n, dA_array, ldda, ipiv_array, info_array, batchsize));
}

template <>
void getrfBatched<float>(
    int n, float** dA_array, int ldda, int* ipiv_array, int* info_array, int batchsize) {
  auto handle = at::zoom::getCurrentHIPBlasHandle();
  TORCH_HIPBLAS_CHECK(hipblasSgetrfBatched(
      handle, n, dA_array, ldda, ipiv_array, info_array, batchsize));
}

template <>
void getrfBatched<c10::complex<double>>(
    int n,
    c10::complex<double>** dA_array,
    int ldda,
    int* ipiv_array,
    int* info_array,
    int batchsize) {
  auto handle = at::zoom::getCurrentHIPBlasHandle();
  TORCH_HIPBLAS_CHECK(hipblasZgetrfBatched(
      handle,
      n,
      reinterpret_cast<hipDoubleComplex**>(dA_array),
      ldda,
      ipiv_array,
      info_array,
      batchsize));
}

template <>
void getrfBatched<c10::complex<float>>(
    int n,
    c10::complex<float>** dA_array,
    int ldda,
    int* ipiv_array,
    int* info_array,
    int batchsize) {
  auto handle = at::zoom::getCurrentHIPBlasHandle();
  TORCH_HIPBLAS_CHECK(hipblasCgetrfBatched(
      handle,
      n,
      reinterpret_cast<hipComplex**>(dA_array),
      ldda,
      ipiv_array,
      info_array,
      batchsize));
}


template <>
void gelsBatched<double>(CUDABLAS_GELS_BATCHED_ARGTYPES(double)) {
  TORCH_HIPBLAS_CHECK(hipblasDgelsBatched(
      handle, trans, m, n, nrhs, dA_array, ldda, dC_array, lddc, info, devInfoArray, batchSize));
}

template <>
void gelsBatched<float>(CUDABLAS_GELS_BATCHED_ARGTYPES(float)) {
  TORCH_HIPBLAS_CHECK(hipblasSgelsBatched(
      handle, trans, m, n, nrhs, dA_array, ldda, dC_array, lddc, info, devInfoArray, batchSize));
}

template <>
void gelsBatched<c10::complex<double>>(CUDABLAS_GELS_BATCHED_ARGTYPES(c10::complex<double>)) {
  TORCH_HIPBLAS_CHECK(hipblasZgelsBatched(
      handle, trans,
      m, n, nrhs,
      reinterpret_cast<hipDoubleComplex**>(dA_array),
      ldda,
      reinterpret_cast<hipDoubleComplex**>(dC_array),
      lddc,
      info,
      devInfoArray,
      batchSize));
}

template <>
void gelsBatched<c10::complex<float>>(CUDABLAS_GELS_BATCHED_ARGTYPES(c10::complex<float>)) {
  TORCH_HIPBLAS_CHECK(hipblasCgelsBatched(
      handle, trans,
      m, n, nrhs,
      reinterpret_cast<hipComplex**>(dA_array),
      ldda,
      reinterpret_cast<hipComplex**>(dC_array),
      lddc,
      info,
      devInfoArray,
      batchSize));
}

} // namespace at::zoom::blas
