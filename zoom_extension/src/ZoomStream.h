#pragma once
#include "ZoomDefines.h"
#include <c10/core/DeviceGuard.h>
#include <c10/core/Stream.h>
#include "ZoomFunctions.h"
#include <c10/util/Exception.h>

namespace c10::zoom {

static constexpr int max_compile_time_stream_priorities = 4;

// Value object representing a CUDA stream.  This is just a wrapper
// around c10::Stream, but it comes with a little extra CUDA-specific
// functionality (conversion to hipStream_t), and a guarantee that
// the wrapped c10::Stream really is a CUDA stream.
class ZoomStream {
 public:
  enum Unchecked { UNCHECKED };

  /// Construct a ZoomStream from a Stream.  This construction is checked,
  /// and will raise an error if the Stream is not, in fact, a CUDA stream.
  explicit ZoomStream(Stream stream) : stream_(stream) {
    TORCH_CHECK(stream_.device_type() == DeviceType::PrivateUse1);
  }

  /// Construct a ZoomStream from a Stream with no error checking.
  /// This constructor uses the "named" constructor idiom, and can
  /// be invoked as: ZoomStream(ZoomStream::UNCHECKED, stream)
  explicit ZoomStream(Unchecked, Stream stream) : stream_(stream) {}

  bool operator==(const ZoomStream& other) const noexcept {
    return unwrap() == other.unwrap();
  }

  bool operator!=(const ZoomStream& other) const noexcept {
    return unwrap() != other.unwrap();
  }

  /// Implicit conversion to hipStream_t.
  operator hipStream_t() const {
    return stream();
  }

  /// Implicit conversion to Stream (a.k.a., forget that the stream is a
  /// CUDA stream).
  operator Stream() const {
    return unwrap();
  }

  /// Used to avoid baking in device type explicitly to Python-side API.
  DeviceType device_type() const {
    return DeviceType::PrivateUse1;
  }

  /// Get the CUDA device index that this stream is associated with.
  DeviceIndex device_index() const {
    return stream_.device_index();
  }

  /// Get the full Device that this stream is associated with.  The Device
  /// is guaranteed to be a CUDA device.
  Device device() const {
    return Device(DeviceType::PrivateUse1, device_index());
  }

  /// Return the stream ID corresponding to this particular stream.
  StreamId id() const {
    return stream_.id();
  }

  bool query() const {
    DeviceGuard guard{stream_.device()};
    hipError_t err = C10_ZOOM_ERROR_HANDLED(hipStreamQuery(stream()));

    if (err == hipSuccess) {
      return true;
    } else if (err != hipErrorNotReady) {
      C10_ZOOM_CHECK(err);
    } else {
      // ignore and clear the error if not ready
      (void)hipGetLastError();
    }

    return false;
  }

  void synchronize() const {
    DeviceGuard guard{stream_.device()};
    c10::zoom::stream_synchronize(stream());
  }

  int priority() const {
    DeviceGuard guard{stream_.device()};
    int priority = 0;
    C10_ZOOM_CHECK(hipStreamGetPriority(stream(), &priority));
    return priority;
  }

  /// Explicit conversion to hipStream_t.
  hipStream_t stream() const;

  /// Explicit conversion to Stream.
  Stream unwrap() const {
    return stream_;
  }

  /// Reversibly pack a ZoomStream into a struct representation.
  /// Previously the stream's data was packed into a single int64_t,
  /// as it was assumed the fields would not require more than
  /// 64 bits of storage in total.
  /// See https://github.com/pytorch/pytorch/issues/75854
  /// for more information regarding newer platforms that may violate
  /// this assumption.
  ///
  /// The ZoomStream can be unpacked using unpack().
  struct c10::StreamData3 pack3() const {
    return stream_.pack3();
  }

  // Unpack a ZoomStream from the 3 fields generated by pack().
  static ZoomStream unpack3(
      StreamId stream_id,
      DeviceIndex device_index,
      DeviceType device_type) {
    return ZoomStream(Stream::unpack3(stream_id, device_index, device_type));
  }

  static std::tuple<int, int> priority_range() {
    // Note: this returns the range of priority **supported by PyTorch**, not
    // the range of priority **supported by CUDA**. The former is a subset of
    // the latter.
    int least_priority = 0, greatest_priority = 0;
    C10_ZOOM_CHECK(
        hipDeviceGetStreamPriorityRange(&least_priority, &greatest_priority));

    // See Note [HIP stream priorities]
    TORCH_INTERNAL_ASSERT(
        least_priority == 1, "Unexpected HIP stream priority range");
    least_priority = 0;

    TORCH_INTERNAL_ASSERT(
        greatest_priority <= -1, "Unexpected HIP stream priority range");
    greatest_priority = std::max(
        -c10::zoom::max_compile_time_stream_priorities + 1, greatest_priority);
    return std::make_tuple(least_priority, greatest_priority);
  }

  // Deleted for now; use CUDAEvent::block instead
  // void synchronize_with(const CUDAEvent& event) const;

 private:
  Stream stream_;
};

/**
 * Get a new stream from the CUDA stream pool.  You can think of this
 * as "creating" a new stream, but no such creation actually happens;
 * instead, streams are preallocated from the pool and returned in a
 * round-robin fashion.
 *
 * You can request a stream from the high priority pool by setting
 * isHighPriority to true, or a stream for a specific device by setting device
 * (defaulting to the current CUDA stream.)
 */
ZoomStream
getStreamFromPool(const bool isHighPriority = false, DeviceIndex device = -1);
// no default priority to disambiguate overloads
ZoomStream
getStreamFromPool(const int priority, DeviceIndex device = -1);

/**
 * Get a ZoomStream from a externally allocated one.
 *
 * This is mainly for interoperability with different libraries where we
 * want to operate on a non-torch allocated stream for data exchange or similar
 * purposes
 */
ZoomStream
getStreamFromExternal(hipStream_t ext_stream, DeviceIndex device_index);

/**
 * Get the default CUDA stream, for the passed CUDA device, or for the
 * current device if no device index is passed.  The default stream is
 * where most computation occurs when you aren't explicitly using
 * streams.
 */
ZoomStream getDefaultZoomStream(DeviceIndex device_index = -1);

/**
 * Get the current CUDA stream, for the passed CUDA device, or for the
 * current device if no device index is passed.  The current CUDA stream
 * will usually be the default CUDA stream for the device, but it may
 * be different if someone called 'setCurrentZoomStream' or used 'StreamGuard'
 * or 'ZoomStreamGuard'.
 */
ZoomStream getCurrentZoomStream(DeviceIndex device_index = -1);

/**
 * Set the current stream on the device of the passed in stream to be
 * the passed in stream.  Yes, you read that right: this function
 * has *nothing* to do with the current device: it toggles the current
 * stream of the device of the passed stream.
 *
 * Confused?  Avoid using this function; prefer using 'ZoomStreamGuard' instead
 * (which will switch both your current device and current stream in the way you
 * expect, and reset it back to its original state afterwards).
 */
void setCurrentZoomStream(ZoomStream stream);

std::ostream& operator<<(std::ostream& stream, const ZoomStream& s);

} // namespace c10::zoom

namespace std {
template <>
struct hash<c10::zoom::ZoomStream> {
  size_t operator()(c10::zoom::ZoomStream s) const noexcept {
    return std::hash<c10::Stream>{}(s.unwrap());
  }
};
} // namespace std